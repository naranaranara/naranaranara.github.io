---
layout: post
title:  "PINN 코드 수정"
toc: true          # 우측 목차
toc_sticky: true   # 스크롤해도 고정
date: 2025-12-24
tags: [markdown, blog]
use_math: true
mathjax: true
---
## 문제점  

1\. 논문과 코드의 결과값의 오차가 너무 큼  
2\. 수식으로 계산한 해석해 값의 불일치  
3\. 해석을 돌릴 때마다 값이 바뀜

## 해결방법

1\. backend 수정  
2\. visualization 수정  
3\. 코드 분석

### backend 수정  

DeepXDE는 여러개의 딥러닝 엔진을 사용한다. 여기에는 tensorflow.compat.v1, tensorflow, pytorch, jax, paddle가 있다.  
이러한 딥러닝 엔진들은 딥러닝 계산을 해주는 역할을 한다.  

**1\.텐서계산** : 수학 연산을 빠르게 처리  
**2\.자동미분** : 손실함수 $L$을 줄이려면 미분이 필요한데 이걸 사람이 유도하지 않아도 계산 그래프를 따라서 자동으로 구해줌.  
**3\.가속실행** : 하드웨어에서 빠르게 돌릴 수 있게 해줌.  

각각의 딥러닝 엔진들은 torch.*, tf.*, jax.*, paddle.*와 같이 코드에서 호출되는 함수가 다르다.  

논문에서 제공된 코드에서 contact_utils.py와 elasticity_utils.py 에는 torch.*로 하드코딩이 되어있었다.  
그래서 DeepXDE backend가 TensorFlow일 때도 torch.*로 호출될 수 있어서 에러가 나거나 불안정했다.  
따라서 DeepXDE가 선택한 backend에 맞게 연산을 자동으로 선택하도록 코드를 수정하였다.  

```contact_utils.py``` 수정  

**변견 전**  

```python
return 1/(1+torch.exp(-delta*x))
```

**변경 후**  

```python
current_backend = backend_options[backend_name]
return 1/(1 + current_backend.exp(-delta*x))
```

cond가 numpy bool 마스크이고 선택 대상은 backend 텐서라서 조합이 불안정했다.  
boolean indexing을 하려면 cond가 torch.bool 텐서여야 한다. 하지만 DeepXDE에서는 cond가 numpy에서 만들어지는 경우가 많다.  
지금처럼 pytorch인 경우 ```values[cond]```를 사용하게 되면 values는 torch 텐서이고 cond는 numpy 배열이여서 위험하다.  

따라서 bool_mask 자체를 버리고, True인 위치의 인덱스 목록으로 바꿔주는 함수를 만들었다.  

**변경 전**  

```python
sigma_xx_n_x = sigma_xx[cond] * nx

num = gap_y[cond]
```

**변경 후**  

```python
def _select_rows(values, cond):
    """Select boundary rows from a (N, ...) backend tensor using a numpy boolean mask."""
    idx = np.nonzero(cond)[0]
    if backend_name == "pytorch":
        idx_t = torch.as_tensor(idx, dtype=torch.long, device=values.device)
        return values.index_select(0, idx_t)
    return tf.gather(values, idx)
```

### Visualization(해석해 계산)부분 수정  

처음 논문 제공 코드에는 해석해를 극좌표계를 사용했고, 응력이 x 방향으로 작용하고 있었다.  

이를 논문에서 사용한 수식과, 응력이 y축으로 작용하는 것으로 코드를 수정하였다.  

<img width="709" height="297" alt="image" src="https://github.com/user-attachments/assets/c30ffb67-43c6-489c-87f8-13cdd12935b5" />  

$$
u_x = \frac{-p}{E} \nu (1 + \nu)x, \quad u_y = \frac{p}{E} (1 - \nu^2)y

\sigma_{yy} = -p, \quad \sigma_{xy} = 0
$$

**변경 전**  

```python
theta = np.degrees(np.arctan2(X[:, 1], X[:, 0])).reshape(-1, 1)  
theta_radian = (theta - 90) * np.pi / 180                      

sigma_rr     = ext_traction/2 + ext_traction/2 * np.cos(2 * theta_radian)
sigma_theta  = ext_traction/2 - ext_traction/2 * np.cos(2 * theta_radian)
sigma_rtheta = -ext_traction/2 * np.sin(2 * theta_radian)

sigma_combined_radial = np.hstack((sigma_rr, sigma_theta, sigma_rtheta))  

theta_radian_flat = theta_radian.flatten()
A = [[np.cos(theta_radian_flat)**2, np.sin(theta_radian_flat)**2, 2*np.sin(theta_radian_flat)*np.cos(theta_radian_flat)],
     [np.sin(theta_radian_flat)**2, np.cos(theta_radian_flat)**2, -2*np.sin(theta_radian_flat)*np.cos(theta_radian_flat)],
     [-np.sin(theta_radian_flat)*np.cos(theta_radian_flat), np.sin(theta_radian_flat)*np.cos(theta_radian_flat),
      np.cos(theta_radian_flat)**2 - np.sin(theta_radian_flat)**2]]
A = np.array(A)  # shape (3,3,N)

sigma_analytical = np.zeros((len(sigma_rr), 3))  # columns: [sigma_xx, sigma_yy, sigma_xy]

for i in range(len(sigma_rr)):
    sigma_analytical[i:i+1, :] = (
        np.matmul(np.linalg.inv(A[:, :, i]), sigma_combined_radial.T[:, i:i+1]).T
    )

sigma_analytical_temp = sigma_analytical.copy()
sigma_analytical[:, 0] = sigma_analytical_temp[:, 1]
sigma_analytical[:, 1] = sigma_analytical_temp[:, 0]
```

**변경 후**  

```python
output = model.predict(X)
sigma_xx_pred, sigma_yy_pred, sigma_xy_pred = output[:, 2], output[:, 3], output[:, 4]

x_coord = X[:, 0]
y_coord = X[:, 1]

sigma_xx_analy = np.zeros_like(x_coord)
sigma_yy_analy = np.full_like(y_coord, ext_traction)  
sigma_xy_analy = np.zeros_like(x_coord)

error_sxx = np.abs(sigma_xx_pred - sigma_xx_analy)
error_syy = np.abs(sigma_yy_pred - sigma_yy_analy)
error_sxy = np.abs(sigma_xy_pred - sigma_xy_analy)

combined_error_stress = (error_sxx, error_syy, error_sxy)
```

### 코드 분석  

매번 해석마다 모델이 예측한 해가 달라지는 원인은 초기 가중치가 랩덤이고, 학습점 자체가 바뀐다.  

초기 가중치가 매번 달라서 최적화 경로가 달라진다.  

```python
initializer = "Glorot uniform"
```

학습점을 Sobol 형식으로 했기 때문이다.  
Sobol은 PINN에서 도메인을 더 골고루 검사하려고 쓰는 준랜덤 샘플링 시퀀스이다.  
일반 랜덤은 학습점이 몰리거나 듬성듬성한 부분이 생길 수 있다.  
Sobol은 전체 공간을 균일하게 커버할 수 있도록 해준다.  

```python
data = dde.data.PDE(
    geom,
    pde_mixed_plane_stress,
    bcs_,
    num_domain=n_dummy,
    num_boundary=n_dummy,
    num_test=None,
    train_distribution = "Sobol"
)
```

## 결과  

<img width="1099" height="689" alt="image" src="https://github.com/user-attachments/assets/ad198552-f528-453d-8040-a404dc4e674a" />  

위에서부터 차례대로 sign, sigmoid, fischer-burmeister 방법이다.  

각 방법의 train 시간은  

sign : 729.663452 s  
sigmoid : 798.736885 s  
fischer-burmeister : 616.068206 s  

fischer-burmeister가 가장 정확한 결과를 보인다는 것을 알 수 있다. 







